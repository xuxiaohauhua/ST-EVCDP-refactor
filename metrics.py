"""
è¯„ä¼°æŒ‡æ ‡è®¡ç®—
"""
import numpy as np
import torch
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from typing import Dict, Union


def calculate_metrics(y_true: Union[np.ndarray, torch.Tensor], 
                     y_pred: Union[np.ndarray, torch.Tensor]) -> Dict[str, float]:
    """
    è®¡ç®—æ—¶åºé¢„æµ‹çš„è¯„ä¼°æŒ‡æ ‡
    
    Args:
        y_true: çœŸå®å€¼
        y_pred: é¢„æµ‹å€¼
        
    Returns:
        Dict[str, float]: åŒ…å«å„ç§è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
    """
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    if isinstance(y_true, torch.Tensor):
        y_true = y_true.detach().cpu().numpy()
    if isinstance(y_pred, torch.Tensor):
        y_pred = y_pred.detach().cpu().numpy()
    
    # å±•å¹³æ•°ç»„ç”¨äºè®¡ç®—
    y_true_flat = y_true.flatten()
    y_pred_flat = y_pred.flatten()
    
    # ç§»é™¤NaNå€¼
    mask = ~(np.isnan(y_true_flat) | np.isnan(y_pred_flat))
    y_true_clean = y_true_flat[mask]
    y_pred_clean = y_pred_flat[mask]
    
    if len(y_true_clean) == 0:
        return {
            'MSE': np.nan,
            'RMSE': np.nan,
            'MAE': np.nan,
            'MAPE': np.nan,
            'R2': np.nan,
            'RAE': np.nan
        }
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    mse = mean_squared_error(y_true_clean, y_pred_clean)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true_clean, y_pred_clean)
    
    # MAPE (Mean Absolute Percentage Error)
    mape = np.mean(np.abs((y_true_clean - y_pred_clean) / (y_true_clean + 1e-8))) * 100
    
    # RÂ² (å†³å®šç³»æ•°)
    r2 = r2_score(y_true_clean, y_pred_clean)
    
    # RAE (Relative Absolute Error)
    rae = np.sum(np.abs(y_true_clean - y_pred_clean)) / (np.sum(np.abs(y_true_clean - np.mean(y_true_clean))) + 1e-8)
    
    return {
        'MSE': float(mse),
        'RMSE': float(rmse),
        'MAE': float(mae),
        'MAPE': float(mape),
        'R2': float(r2),
        'RAE': float(rae)
    }


def calculate_directional_accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """
    è®¡ç®—æ–¹å‘å‡†ç¡®ç‡ (é¢„æµ‹è¶‹åŠ¿æ˜¯å¦æ­£ç¡®)
    
    Args:
        y_true: çœŸå®å€¼
        y_pred: é¢„æµ‹å€¼
        
    Returns:
        float: æ–¹å‘å‡†ç¡®ç‡ (0-1)
    """
    if len(y_true) < 2 or len(y_pred) < 2:
        return 0.0
        
    true_diff = np.diff(y_true.flatten())
    pred_diff = np.diff(y_pred.flatten())
    
    correct_directions = (true_diff * pred_diff) >= 0
    return np.mean(correct_directions)


def calculate_peak_detection_accuracy(y_true: np.ndarray, y_pred: np.ndarray, 
                                    threshold: float = 0.1) -> Dict[str, float]:
    """
    è®¡ç®—å³°å€¼æ£€æµ‹å‡†ç¡®ç‡
    
    Args:
        y_true: çœŸå®å€¼
        y_pred: é¢„æµ‹å€¼
        threshold: å³°å€¼åˆ¤å®šé˜ˆå€¼
        
    Returns:
        Dict[str, float]: å³°å€¼æ£€æµ‹ç›¸å…³æŒ‡æ ‡
    """
    from scipy.signal import find_peaks
    
    y_true_flat = y_true.flatten()
    y_pred_flat = y_pred.flatten()
    
    # æ‰¾åˆ°çœŸå®å³°å€¼
    true_peaks, _ = find_peaks(y_true_flat, height=np.mean(y_true_flat) + threshold * np.std(y_true_flat))
    
    # æ‰¾åˆ°é¢„æµ‹å³°å€¼
    pred_peaks, _ = find_peaks(y_pred_flat, height=np.mean(y_pred_flat) + threshold * np.std(y_pred_flat))
    
    if len(true_peaks) == 0:
        return {'peak_precision': 0.0, 'peak_recall': 0.0, 'peak_f1': 0.0}
    
    # è®¡ç®—å³°å€¼åŒ¹é… (å…è®¸ä¸€å®šçš„æ—¶é—´åç§»)
    tolerance = 3  # å…è®¸3ä¸ªæ—¶é—´æ­¥çš„åç§»
    matched_peaks = 0
    
    for true_peak in true_peaks:
        if any(abs(pred_peak - true_peak) <= tolerance for pred_peak in pred_peaks):
            matched_peaks += 1
    
    precision = matched_peaks / len(pred_peaks) if len(pred_peaks) > 0 else 0.0
    recall = matched_peaks / len(true_peaks)
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    
    return {
        'peak_precision': precision,
        'peak_recall': recall,
        'peak_f1': f1
    }


def calculate_quantile_loss(y_true: np.ndarray, y_pred: np.ndarray, 
                          quantiles: list = [0.1, 0.5, 0.9]) -> Dict[str, float]:
    """
    è®¡ç®—åˆ†ä½æ•°æŸå¤± (ç”¨äºæ¦‚ç‡é¢„æµ‹è¯„ä¼°)
    
    Args:
        y_true: çœŸå®å€¼
        y_pred: é¢„æµ‹å€¼
        quantiles: åˆ†ä½æ•°åˆ—è¡¨
        
    Returns:
        Dict[str, float]: å„åˆ†ä½æ•°çš„æŸå¤±
    """
    losses = {}
    
    for q in quantiles:
        error = y_true - y_pred
        loss = np.mean(np.maximum(q * error, (q - 1) * error))
        losses[f'quantile_loss_{q}'] = float(loss)
    
    return losses


def print_metrics_summary(metrics: Dict[str, float]):
    """
    æ‰“å°æŒ‡æ ‡æ‘˜è¦
    
    Args:
        metrics: æŒ‡æ ‡å­—å…¸
    """
    print("\n" + "="*50)
    print("æ¨¡å‹è¯„ä¼°æŒ‡æ ‡æ‘˜è¦")
    print("="*50)
    
    print(f"{'æŒ‡æ ‡':<15} {'æ•°å€¼':<15} {'æè¿°'}")
    print("-"*50)
    print(f"{'MSE':<15} {metrics.get('MSE', 0):<15.6f} å‡æ–¹è¯¯å·®")
    print(f"{'RMSE':<15} {metrics.get('RMSE', 0):<15.6f} å‡æ–¹æ ¹è¯¯å·®")
    print(f"{'MAE':<15} {metrics.get('MAE', 0):<15.6f} å¹³å‡ç»å¯¹è¯¯å·®")
    print(f"{'MAPE (%)':<15} {metrics.get('MAPE', 0):<15.6f} å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®")
    print(f"{'RÂ²':<15} {metrics.get('R2', 0):<15.6f} å†³å®šç³»æ•°")
    print(f"{'RAE':<15} {metrics.get('RAE', 0):<15.6f} ç›¸å¯¹ç»å¯¹è¯¯å·®")
    
    print("\n" + "="*50)
    print("æ€§èƒ½è¯„ä¼°:")
    if metrics.get('MAPE', 100) < 10:
        print("âœ… ä¼˜ç§€ (MAPE < 10%)")
    elif metrics.get('MAPE', 100) < 20:
        print("ğŸŸ¡ è‰¯å¥½ (MAPE < 20%)")
    else:
        print("ğŸ”´ éœ€è¦æ”¹è¿› (MAPE >= 20%)")
    print("="*50)